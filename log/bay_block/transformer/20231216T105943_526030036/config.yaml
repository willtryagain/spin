adj_threshold: 0.1
axis: both
batch_inference: 32
batch_size: 8
batches_epoch: 300
condition_on_u: true
config: imputation/transformer.yaml
cut_edges_uniformly: false
dataset_name: bay_block
dropout: 0
epochs: 300
ff_size: 128
grad_clip_val: 5.0
hidden_size: 64
horizon_lag: 1
l2_reg: 0.0
loss_fn: l1_loss
lr: 0.0008
lr_scheduler: magic
mask_scaling: true
max_edges_subgraph: 1000
model_name: transformer
n_heads: 4
n_hops: 2
n_layers: 5
n_roots_subgraph: null
patience: 40
precision: 16
prediction_loss_weight: 1.0
scale_target: true
seed: 526030036
split_batch_in: 1
stride: 1
test_len: 0.2
val_len: 0.1
whiten_prob:
- 0.2
- 0.5
- 0.8
window: 24
window_lag: 1
workers: 0
